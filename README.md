# Local Spark Dev Env with Docker

Development environment for k8s.

Using a kubernetes image build to be ready for Azure Data Lake Storage Gen2 and Delta Lake.

## Options

You can choose to do your development on an interactive notebook with jupyter lab, run your script with spark-submit or submit your job to a local Kubernetes. 

* With spark submit
    * Use the tutorial inside spark-submit-dev

* With Jupyter Lab
    * Use the tutorial inside jupyspark-env

* With Kubernetes cluster
    * Use the tutorial inside k8s
